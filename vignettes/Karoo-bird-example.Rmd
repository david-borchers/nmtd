---
title: "Worked example: Karoo bird data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Worked example: Karoo bird data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


This vignette shows a worked example of how the `nmtd` package can be used to fit various models to data. As an example, we are using the `Karoodata` data set that comes with the package. See the helpfile for more information on this data set and its origin.

```{r setup, message=F}
library(nmtd)
library(tidyverse)
library(kableExtra)
```

## Getting the data ready

We first load the data frame and have a quick look at it:

```{r}
data("Karoodata")
str(Karoodata)
names(Karoodata)
```

The data set consists of 10-minute bird counts carried out at points (`survey_id`) throughout the Karoo region in South Africa. All bird species that were seen or heard were noted down, along with the exact time at which the first individual of a species was encountered. A number of covariates were also recorded. Multiple point counts were carried out at each site (`pentad`), which are grid cells of 5' $\times$ 5' (longitude, latitude).

In total, there were `r length(unique(Karoodata$survey_id))` surveys to `r length(unique(Karoodata$pentad))` sites. Each site received between 10 and 20 surveys:

```{r}
nsurveys <- Karoodata %>%
  group_by(pentad) %>%
  summarise(surveys = length(unique(survey_id)))

# some data exploration
hist(nsurveys$surveys, main = "", xlab = "Number of surveys")
```

We find that sparse data pose a challenge for abundance models, even when we have time-to-detection data. When most surveys result in no detection for a species, then there is just not enough information to reliably estimate abundance for that species.

Let's therefore see what the most common species are in this data set:

```{r}
karootbl <- table(Karoodata$pentad, Karoodata$species)

# looking for the most common species:
head(sort(apply(karootbl, 2, sum), decreasing = T)) # number of detections by species
head(sort(apply(karootbl, 2, function(x){sum(x>0)}), decreasing = T)) # number of detections by species
```

For our purposes here, we choose a single species, the rufous-eared warbler (*Malcorus pectoralis*), an attractive warbler that is quite common in the region. 

We need to aggregate our data so that we have one line per survey. For each survey, we need to know whether a rufous-eared warbler was detected and what the time to detection (`ttd`) was. If no rufous-eared warbler was detected during the survey, we set `ttd` equal to the maximum, i.e. 660 seconds (recall that each survey lasted 10 minutes).

```{r}
# detections:
bdata <- Karoodata[Karoodata$species == "Rufous-eared Warbler", c("survey_id", "pentad", "ttd")]

# non-detections:
bdata.nd <- Karoodata[Karoodata$species != "Rufous-eared Warbler", c("survey_id", "pentad")]

# we only need one non-detection per survey
bdata.nd <- bdata.nd %>%
  group_by(survey_id) %>%
  summarise(pentad = first(pentad), ttd = 660)

bdata <- rbind(bdata, bdata.nd)

# get rid of non-detections for surveys where we also had a detection
bdata <- bdata %>%
  group_by(survey_id) %>%
  summarise(pentad = first(pentad), ttd = min(ttd))

head(bdata, n=20)
```

We now have a data frame with one line per survey. It gives the time to detection if a rufous-eared warbler was detected and the maximum survey time otherwise. We now need to get this into the format that the function `nll.binT1` expects, with one row per site and the columns corresponding to the repeat surveys, holding detection times.

```{r}
bdata_wide <- bdata[,-1] %>%
  group_by(pentad) %>%
  mutate(row = row_number()) %>%
  tidyr::pivot_wider(names_from = row, values_from = ttd)

head(bdata_wide)
```

All sites have at least 10 visits but some sites have more. At the moment, the functions can only deal with a fixed number of visits to each site. We therefore take the first 10 visits to each site and discard the rest of the data.

While we are at it, we also prepare the input data for the model `Binary:M`, where we only use detections and non-detection, i.e. we discard the information on time to detection.

```{r}
bdata_ttd <- bdata_dnd <- bdata_wide[,2:11]
bdata_dnd[bdata_dnd < 660]  <- 1
bdata_dnd[bdata_dnd == 660]  <- 0
```

So, in this final data set, we have `r dim(bdata_ttd)[2]` surveys to `r dim(bdata_ttd)[1]` sites, i.e. `r dim(bdata_ttd)[2] * dim(bdata_ttd)[1]` surveys in total. Rufous-eared warblers were detected on `r sum(bdata_dnd)` surveys at `r sum(apply(bdata_dnd, 1, max))` of the sites.

On most sites where rufous-eared warbler were detected, they were encountered fairly early during the survey:

```{r, echo=F}
hist(bdata_ttd[bdata_ttd < 660], main = "", xlab = "Time to detection [s]")
```

<!-- We find that rescaling the detection times so that the maximum is 1 helps with convergence. -->

<!-- ```{r} -->
<!-- bdata_ttd <- bdata_ttd/max(bdata_ttd) -->
<!-- ``` -->

We are now ready to fit the models to the data.

We first fit the model using time-to-detection data, `BinaryT1:M`:

```{r}
fit_binT1M <- optim(c(log(10), log(0.001)), nll.binT1M, R = dim(bdata_ttd)[1], 
                    J = dim(bdata_ttd)[2], Tmax = 660, dat = as.matrix(bdata_ttd),
                    hessian=TRUE)
estpar_binT1M=fit_binT1M$par
est = exp(estpar_binT1M) # point estimate
names(est) = c("lambda","h")
vcv = solve(fit_binT1M$hessian) # variance-covariance matrix
# now get 95% confidence bound estimates
lower = exp(estpar_binT1M - 1.96*sqrt(diag(vcv)))
upper = exp(estpar_binT1M + 1.96*sqrt(diag(vcv)))
estdf = data.frame(est=signif(est,3), lcl=signif(lower,3), 
                   ucl=signif(upper,3),ci.width=signif(upper-lower,3))
kable(estdf)
```

Then we fit the model using only detection / non-detection data, `Binary:M`:

```{r}
fit_binM <- optim(c(log(10), log(0.001)), nll.binM, R = dim(bdata_ttd)[1], J = dim(bdata_ttd)[2], 
                  Tmax = 660, dat = as.matrix(bdata_dnd),hessian=TRUE)
estpar_binM=fit_binM$par
est = exp(estpar_binM) # point estimate
names(est) = c("lambda","h")
vcv = solve(fit_binM$hessian) # variance-covariance matrix
# now get 95% confidence bound estimates
lower = exp(estpar_binM - 1.96*sqrt(diag(vcv)))
upper = exp(estpar_binM + 1.96*sqrt(diag(vcv)))
estdf = data.frame(est=signif(est,3), lcl=signif(lower,3), ucl=signif(upper,3), 
                   ci.width=signif(upper-lower,3))
kable(estdf)
```